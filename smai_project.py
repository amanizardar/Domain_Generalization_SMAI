# -*- coding: utf-8 -*-
"""SMAI_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12MPoDalftlSsnC4Fj97dGNpMF2HCRhjP
"""

import torch





dataset={}
dataset["PACS"] = ["art_painting", "cartoon", "photo", "sketch"]
x=dataset["PACS"]

print(x)
print(type(x))
print(len(x))

print(x[-1])

from matplotlib import pyplot as plt
from PIL import Image
import matplotlib.image as mpimg
import numpy as np
from PIL import Image
from torchvision import transforms


import os

class_dict={
    "dog":0,
    "elephant":1,
    "giraffe":2,
    "guitar":3,
    "horse":4,
    "house":5,
    "person":6
}

opt = {
    'image_size': 32,
    'is_grayscale': False,
    'val_split': 0.75
}
def load_image(path):
    im = Image.open(path).convert('L' if opt['is_grayscale'] else 'RGB')
    im = im.resize((opt['image_size'],opt['image_size']))
    im = np.array(im)
    im = im/256
    return im
def display_images(imgs,classes,row=1,col=2,w=3,h=3):
    fig=plt.figure(figsize=(2, 2))
    for i in range(1, col*row +1):
        img = imgs[i-1]
        fig.add_subplot(row, col, i)
        
        if opt['is_grayscale']:
            plt.imshow(img , cmap='gray') 
        else:
            plt.imshow(img)
        
        # plt.title("Class:{}".format(classes[i-1]))
        # plt.axis('off')
    plt.show()

def load_data(dir_path,class_name):
    image_list = []
    y_list = []
    filenames=[]
    label_dict = class_dict
    for filename in sorted(os.listdir(dir_path)):
        if filename.endswith(".jpg") or filename.endswith(".png"):
            im = load_image(os.path.join(dir_path,filename))
            # y = filename.split('_')[0]
            y = label_dict[class_name] 
            image_list.append(im)
            filenames.append(filename)
            y_list.append(y)
        else:
            continue
    image_list = np.array(image_list)
    y_list = np.array(y_list)
    print("Dataset shape:",image_list.shape)
    #print("Label shape:",y_list.shape)

    return image_list,y_list,filenames

dirpath = '/content/drive/MyDrive/smai/PACS/pacs_data/photo/giraffe/'
# dirpath='/content/drive/MyDrive/smai/PACS/pacs_data/sketch/elephant/'
X,y,filenames = load_data(dirpath,"giraffe")



print(y)

len(filenames)
print(filenames)

# print(X[0].shape)
print(type(X))

display_images(X,0)

class_labels=["dog","elephant","giraffe","guitar","horse","house","person"]
data_types=["art_painting","cartoon","photo",'sketch']

path="/content/drive/MyDrive/smai/PACS/pacs_data/"

# complete_data=[]
art_train=[]
art_val=[]
art_test=[]
cartoon_train=[]
cartoon_val=[]
cartoon_test=[]
photo_train=[]
photo_val=[]
photo_test=[]
# cartoon_train=[]
# cartoon_val=[]
# cartoon_test=[]
# complete_art=[]

for data_type in data_types:
  complete_data=[]
  y_labels=[]
  print(data_type)
  for class_label in class_labels:
    new_path=path+"/"+data_type+"/"+class_label+"/"
    X,y,filenames = load_data(new_path,class_label)
    
    # complete_data.append(X)
    #display_images(X,0)
    # len=len(X)
    for i in X:
      complete_data.append(i)
    for j in y:
      y_labels.append(j)
  if data_type=="art_painting":
    complete_art=complete_data
    complete_art_labels=y_labels
  if data_type=="cartoon":
    complete_cartoon=complete_data
    complete_cartoon_labels=y_labels
  if data_type=="photo":
    complete_photo=complete_data
    complete_photo_labels=y_labels
  if data_type=="sketch":
    complete_sketch=complete_data
    complete_sketch_labels=y_labels

complete_photo=np.array(complete_photo)
complete_photo_labels=np.array(complete_photo_labels)
print(complete_photo.shape)
print(complete_photo_labels.shape)
print(complete_photo_labels)

#for verification
count=[0,0,0,0,0,0,0]
for i in complete_photo_labels:
  count[i]=count[i]+1
print(count)

plt.figure(figsize = (2,2))
plt.imshow(X[0])



# ############################################################################################################







img = mpimg.imread('pic.jpg')
imgplot = plt.imshow(img)
plt.show()



input_image = Image.open("pic.jpg")
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
input_tensor = preprocess(input_image)
input_batch = input_tensor.unsqueeze(0)











img.shape



# model_ft = model.resnet18(pretrained=True)
model_ft = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)
### strip the last layer
feature_extractor = torch.nn.Sequential(*list(model_ft.children())[:-1])
### check this works

# x = torch.randn([1,3,224,224])

with torch.no_grad():
    output = feature_extractor(input_batch)
# output = feature_extractor(input_batch) # output now has the features corresponding to input x
print(output.shape)

output =output.reshape(512)

output.shape

output







